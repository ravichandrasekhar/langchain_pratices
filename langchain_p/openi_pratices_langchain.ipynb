{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5411e",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0f9f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176a4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"langchain_api_key\"]=os.getenv(\"langchain_api_key\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1561b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000285B64769B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000285B83A60B0> root_client=<openai.OpenAI object at 0x00000285B320FB20> root_async_client=<openai.AsyncOpenAI object at 0x00000285B83A6020> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080eacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a subset of artificial intelligence technologies designed to generate various types of content, including text, images, music, and more, often from a simple prompt or set of parameters. These systems are built on complex models like neural networks, particularly deep learning architectures, which are trained on extensive datasets to understand patterns and structures within the data.\\n\\nThe most common types of generative AI models include:\\n\\n1. **Generative Adversarial Networks (GANs):** These are frameworks where two neural networks, a generator and a discriminator, are pitted against each other. The generator creates new data instances, while the discriminator evaluates them, helping the generator to produce more realistic outputs over time.\\n\\n2. **Variational Autoencoders (VAEs):** These models are used for generating new data by encoding input data into a compressed representation and then decoding it back, allowing for the generation of similar, yet original content.\\n\\n3. **Transformers:** Models like GPT (Generative Pre-trained Transformer) fall under this category. They're particularly effective for generating text by understanding the context and semantics of the data theyâ€™ve been trained on.\\n\\nGenerative AI is increasingly being used in various applications, including:\\n\\n- **Content Creation:** Automating writing for articles, reports, or scripts.\\n- **Design and Art:** Creating original artwork, graphics, and designing objects.\\n- **Music Composition:** Generating music tracks and assisting in the creative process.\\n- **Game Development:** Generating levels, characters, and storyline features.\\n- **Healthcare:** Designing new medical drugs by simulating molecular structures.\\n\\nGenerative AI has a strong potential in areas where creative iteration and innovation are required, although its outputs can sometimes raise ethical questions regarding originality and authenticity.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 348, 'prompt_tokens': 13, 'total_tokens': 361, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_1827dd0c55', 'id': 'chatcmpl-CIcTnSTofNRtaskr9enGqc59YnS5o', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f2192dce-eb37-4352-a9a4-395840fdafef-0' usage_metadata={'input_tokens': 13, 'output_tokens': 348, 'total_tokens': 361, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"what is generative ai?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04362555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d967acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a development tool for building powerful and reliable LLM applications. It offers a suite of features to help developers design, test, evaluate, and monitor applications that leverage large language models (LLMs). Langsmith provides capabilities for:\\n\\n1. **Tracing and Monitoring**: Developers can use Langsmith to trace the execution of language model applications and monitor their performance over time. This includes identifying bottlenecks or failures in the workflow.\\n\\n2. **Dataset Management**: Langsmith allows for the management of datasets to rigorously test the performance of LLMs. It helps in curating representative data that can be used for evaluation and optimization.\\n\\n3. **Evaluation**: By offering tools to evaluate model outputs, Langsmith assists in determining the accuracy and reliability of the application. This involves both automatic metrics as well as human feedback mechanisms.\\n\\n4. **Feedback Integration**: It allows developers to integrate user feedback directly into the development loop, facilitating continuous improvement of the application based on actual user interaction.\\n\\n5. **Visual Interface**: Langsmith often includes visual interfaces that help developers easily understand the workflows, making debugging and optimizing more intuitive.\\n\\nThis toolkit is valuable for developers looking to deploy language model applications at scale with reduced risk and improved reliability.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 33, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_1827dd0c55', 'id': 'chatcmpl-CIcUz0WvQkPi85MRnwBZ79jXOWCpK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--21a5d944-c795-4f2d-82dd-3209ca043579-0' usage_metadata={'input_tokens': 33, 'output_tokens': 250, 'total_tokens': 283, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fdecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e00e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a comprehensive toolkit designed for developers working with language models, aimed at enhancing the development, testing, and deployment of applications that rely on natural language processing. It provides a set of tools and frameworks to streamline workflows when building with language models like those from OpenAI, Hugging Face, and others.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Model Integration and Management**: Simplifies the integration of different language models and allows for easy switching and management, helping developers choose the best models for their needs.\n",
      "\n",
      "2. **Evaluation and Monitoring**: Offers robust tools for evaluating model performance, including accuracy, efficiency, and relevancy of responses, alongside monitoring tools to track these metrics over time in real-world applications.\n",
      "\n",
      "3. **Debugging and Testing Tools**: Provides utilities to create scenarios and test cases, facilitating the identification and resolution of issues in language model outputs.\n",
      "\n",
      "4. **Deployment Support**: Supports the deployment of applications using language models, ensuring that models can be effectively scaled and managed in production environments.\n",
      "\n",
      "5. **Version Control and Experimentation**: Facilitates the management of different model versions, allowing developers to experiment with model variations and configurations safely and effectively.\n",
      "\n",
      "Langsmith aims to reduce the friction experienced when working with language models, empowering developers to build more accurate, reliable, and efficient applications.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
